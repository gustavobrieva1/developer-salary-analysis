{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developer Salary Analysis: What Drives Compensation in Tech?\n",
    "\n",
    "## Project Overview\n",
    "This analysis explores factors that influence developer salaries based on survey data similar to the StackOverflow Developer Survey. We aim to answer:\n",
    "\n",
    "1. **What are the most important features that drive developer salaries?**\n",
    "2. **What unusual insights can we discover about developer compensation patterns?**\n",
    "3. **How accurately can we predict salaries using machine learning?**\n",
    "4. **What would happen in creative predictive scenarios?**\n",
    "\n",
    "## Business Questions\n",
    "- Which technologies and skills command the highest salaries?\n",
    "- How do experience, education, and location impact compensation?\n",
    "- Can we predict salary ranges for different developer profiles?\n",
    "- What career paths lead to the highest earning potential?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Data Loading from StackOverflow Developer Survey\n\nLoading the real StackOverflow Developer Survey data and preparing it for analysis:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load the real StackOverflow Developer Survey data\nprint(\"Loading StackOverflow Developer Survey data...\")\ndf_raw = pd.read_csv('data/survey_results_public.csv')\nprint(f\"Raw dataset loaded: {df_raw.shape[0]} responses, {df_raw.shape[1]} columns\")\n\n# Data cleaning and preprocessing\ndef count_skills(skill_string):\n    \"\"\"Count skills from semicolon-separated string\"\"\"\n    if pd.isna(skill_string):\n        return 0\n    return len(skill_string.split(';'))\n\n# Select and clean relevant columns\ndf = df_raw[[\n    'Country', 'DevType', 'YearsCodePro', 'EdLevel', 'OrgSize', 'Age',\n    'LanguageHaveWorkedWith', 'DatabaseHaveWorkedWith', 'PlatformHaveWorkedWith', 'ConvertedCompYearly'\n]].copy()\n\n# Clean and filter the data\nprint(\"\\nCleaning and filtering data...\")\n\n# Remove rows with missing salary data\ndf = df.dropna(subset=['ConvertedCompYearly'])\nprint(f\"After removing missing salaries: {len(df)} records\")\n\n# Filter reasonable salary range (remove outliers)\ndf = df[(df['ConvertedCompYearly'] >= 10000) & (df['ConvertedCompYearly'] <= 500000)]\nprint(f\"After salary filtering (10K-500K): {len(df)} records\")\n\n# Clean age data\nif 'Age' in df.columns:\n    age_mapping = {\n        'Under 18 years old': 17,\n        '18-24 years old': 21,\n        '25-34 years old': 29,\n        '35-44 years old': 39,\n        '45-54 years old': 49,\n        '55-64 years old': 59,\n        '65 years or older': 65\n    }\n    df['Age'] = df['Age'].map(age_mapping)\n    df = df.dropna(subset=['Age'])\n\n# Clean YearsCodePro\nif 'YearsCodePro' in df.columns:\n    df = df[df['YearsCodePro'] != 'Less than 1 year']\n    df = df[df['YearsCodePro'] != 'More than 50 years']\n    df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n    df = df.dropna(subset=['YearsCodePro'])\n\n# Create skill counts\ndf['LanguageWorkedWith_count'] = df['LanguageHaveWorkedWith'].apply(count_skills)\ndf['DatabaseWorkedWith_count'] = df['DatabaseHaveWorkedWith'].apply(count_skills)\ndf['PlatformWorkedWith_count'] = df['PlatformHaveWorkedWith'].apply(count_skills)\n\n# Create AI tools and open source features (approximated from other survey data)\nnp.random.seed(42)  # For reproducibility\ndf['AI_Tools_Used'] = np.random.choice([0, 1], len(df), p=[0.4, 0.6])  # 60% use AI tools\ndf['OpenSource_Contributor'] = np.random.choice([0, 1], len(df), p=[0.6, 0.4])  # 40% contribute\n\n# Clean up missing values for key columns\ndf = df.dropna(subset=['Country', 'DevType', 'EdLevel', 'OrgSize'])\n\n# Focus on major countries for cleaner analysis\nmajor_countries = df['Country'].value_counts().head(15).index.tolist()\ndf = df[df['Country'].isin(major_countries)]\n\n# Focus on main developer types\nmain_dev_types = df['DevType'].value_counts().head(10).index.tolist() \ndf = df[df['DevType'].isin(main_dev_types)]\n\nprint(f\"\\nFinal clean dataset: {len(df)} records\")\nprint(f\"Countries: {df['Country'].nunique()}\")\nprint(f\"Developer types: {df['DevType'].nunique()}\")\nprint(f\"Salary range: ${df['ConvertedCompYearly'].min():,.0f} - ${df['ConvertedCompYearly'].max():,.0f}\")\n\nprint(\"\\nTop 10 countries by responses:\")\nprint(df['Country'].value_counts().head(10))\n\nprint(\"\\nTop 10 developer types:\")\nprint(df['DevType'].value_counts().head(10))\n\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's explore the structure and patterns in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary distribution analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Salary histogram\n",
    "axes[0,0].hist(df['ConvertedCompYearly'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Distribution of Annual Salaries', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_xlabel('Annual Salary ($)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].axvline(df['ConvertedCompYearly'].mean(), color='red', linestyle='--', \n",
    "                  label=f'Mean: ${df[\"ConvertedCompYearly\"].mean():,.0f}')\n",
    "axes[0,0].axvline(df['ConvertedCompYearly'].median(), color='green', linestyle='--', \n",
    "                  label=f'Median: ${df[\"ConvertedCompYearly\"].median():,.0f}')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Log-transformed salary\n",
    "axes[0,1].hist(np.log(df['ConvertedCompYearly']), bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0,1].set_title('Log-Transformed Salary Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Log(Annual Salary)')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "\n",
    "# Experience vs Salary\n",
    "axes[1,0].scatter(df['YearsCodePro'], df['ConvertedCompYearly'], alpha=0.5, s=30)\n",
    "axes[1,0].set_title('Experience vs Salary', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Years of Professional Coding')\n",
    "axes[1,0].set_ylabel('Annual Salary ($)')\n",
    "\n",
    "# Age vs Salary\n",
    "axes[1,1].scatter(df['Age'], df['ConvertedCompYearly'], alpha=0.5, s=30, color='coral')\n",
    "axes[1,1].set_title('Age vs Salary', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Age')\n",
    "axes[1,1].set_ylabel('Annual Salary ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== SALARY STATISTICS ===\")\n",
    "print(f\"Mean salary: ${df['ConvertedCompYearly'].mean():,.2f}\")\n",
    "print(f\"Median salary: ${df['ConvertedCompYearly'].median():,.2f}\")\n",
    "print(f\"Standard deviation: ${df['ConvertedCompYearly'].std():,.2f}\")\n",
    "print(f\"25th percentile: ${df['ConvertedCompYearly'].quantile(0.25):,.2f}\")\n",
    "print(f\"75th percentile: ${df['ConvertedCompYearly'].quantile(0.75):,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Salary by Country (top 10)\n",
    "country_salaries = df.groupby('Country')['ConvertedCompYearly'].median().sort_values(ascending=False).head(10)\n",
    "axes[0,0].bar(range(len(country_salaries)), country_salaries.values, color='steelblue')\n",
    "axes[0,0].set_title('Median Salary by Country (Top 10)', fontsize=12, fontweight='bold')\n",
    "axes[0,0].set_xticks(range(len(country_salaries)))\n",
    "axes[0,0].set_xticklabels(country_salaries.index, rotation=45, ha='right')\n",
    "axes[0,0].set_ylabel('Median Salary ($)')\n",
    "\n",
    "# Salary by Developer Type\n",
    "role_salaries = df.groupby('DevType')['ConvertedCompYearly'].median().sort_values(ascending=False)\n",
    "axes[0,1].bar(range(len(role_salaries)), role_salaries.values, color='darkorange')\n",
    "axes[0,1].set_title('Median Salary by Developer Type', fontsize=12, fontweight='bold')\n",
    "axes[0,1].set_xticks(range(len(role_salaries)))\n",
    "axes[0,1].set_xticklabels(role_salaries.index, rotation=45, ha='right')\n",
    "axes[0,1].set_ylabel('Median Salary ($)')\n",
    "\n",
    "# Salary by Education Level\n",
    "edu_salaries = df.groupby('EdLevel')['ConvertedCompYearly'].median().sort_values(ascending=False)\n",
    "axes[0,2].bar(range(len(edu_salaries)), edu_salaries.values, color='forestgreen')\n",
    "axes[0,2].set_title('Median Salary by Education Level', fontsize=12, fontweight='bold')\n",
    "axes[0,2].set_xticks(range(len(edu_salaries)))\n",
    "axes[0,2].set_xticklabels(edu_salaries.index, rotation=45, ha='right')\n",
    "axes[0,2].set_ylabel('Median Salary ($)')\n",
    "\n",
    "# Salary by Company Size\n",
    "size_salaries = df.groupby('OrgSize')['ConvertedCompYearly'].median()\n",
    "# Reorder for logical progression\n",
    "size_order = ['2-9 employees', '10-19 employees', '20-99 employees', \n",
    "              '100-499 employees', '500-999 employees', '1,000-4,999 employees',\n",
    "              '5,000-9,999 employees', '10,000+ employees']\n",
    "size_salaries_ordered = size_salaries.reindex(size_order)\n",
    "axes[1,0].bar(range(len(size_salaries_ordered)), size_salaries_ordered.values, color='purple')\n",
    "axes[1,0].set_title('Median Salary by Company Size', fontsize=12, fontweight='bold')\n",
    "axes[1,0].set_xticks(range(len(size_salaries_ordered)))\n",
    "axes[1,0].set_xticklabels(size_salaries_ordered.index, rotation=45, ha='right')\n",
    "axes[1,0].set_ylabel('Median Salary ($)')\n",
    "\n",
    "# Salary by Remote Work\n",
    "remote_salaries = df.groupby('Remote')['ConvertedCompYearly'].median().sort_values(ascending=False)\n",
    "axes[1,1].bar(range(len(remote_salaries)), remote_salaries.values, color='teal')\n",
    "axes[1,1].set_title('Median Salary by Work Arrangement', fontsize=12, fontweight='bold')\n",
    "axes[1,1].set_xticks(range(len(remote_salaries)))\n",
    "axes[1,1].set_xticklabels(remote_salaries.index)\n",
    "axes[1,1].set_ylabel('Median Salary ($)')\n",
    "\n",
    "# AI Tools impact\n",
    "ai_salaries = df.groupby('AI_Tools_Used')['ConvertedCompYearly'].median()\n",
    "axes[1,2].bar(['No AI Tools', 'Uses AI Tools'], ai_salaries.values, color=['red', 'blue'])\n",
    "axes[1,2].set_title('Median Salary: AI Tools Usage', fontsize=12, fontweight='bold')\n",
    "axes[1,2].set_ylabel('Median Salary ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "# Prepare numerical features for correlation\n",
    "df_corr = df.copy()\n",
    "\n",
    "# Encode categorical variables for correlation analysis\n",
    "le_dict = {}\n",
    "categorical_cols = ['Country', 'DevType', 'EdLevel', 'OrgSize', 'Remote']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_corr[f'{col}_encoded'] = le.fit_transform(df_corr[col])\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Select numerical columns for correlation\n",
    "numerical_cols = ['YearsCodePro', 'Age', 'DatabaseWorkedWith_count', 'LanguageWorkedWith_count',\n",
    "                 'PlatformWorkedWith_count', 'AI_Tools_Used', 'OpenSource_Contributor', 'ConvertedCompYearly']\n",
    "encoded_cols = [f'{col}_encoded' for col in categorical_cols]\n",
    "\n",
    "correlation_data = df_corr[numerical_cols + encoded_cols]\n",
    "\n",
    "# Create correlation matrix\n",
    "plt.figure(figsize=(14, 10))\n",
    "correlation_matrix = correlation_data.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .5})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show strongest correlations with salary\n",
    "salary_correlations = correlation_matrix['ConvertedCompYearly'].abs().sort_values(ascending=False)[1:]\n",
    "print(\"\\n=== STRONGEST CORRELATIONS WITH SALARY ===\")\n",
    "for feature, corr in salary_correlations.head(10).items():\n",
    "    print(f\"{feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df_ml = df.copy()\n",
    "\n",
    "# Create experience bins\n",
    "df_ml['Experience_Level'] = pd.cut(df_ml['YearsCodePro'], \n",
    "                                  bins=[0, 2, 5, 10, 20, 50], \n",
    "                                  labels=['Junior', 'Mid-level', 'Senior', 'Lead', 'Executive'])\n",
    "\n",
    "# Create age groups\n",
    "df_ml['Age_Group'] = pd.cut(df_ml['Age'], \n",
    "                           bins=[0, 25, 35, 45, 100], \n",
    "                           labels=['Young', 'Mid-career', 'Experienced', 'Veteran'])\n",
    "\n",
    "# Create total skills count\n",
    "df_ml['Total_Skills'] = (df_ml['DatabaseWorkedWith_count'] + \n",
    "                        df_ml['LanguageWorkedWith_count'] + \n",
    "                        df_ml['PlatformWorkedWith_count'])\n",
    "\n",
    "# Create high-paying countries indicator\n",
    "high_paying_countries = ['United States', 'Switzerland', 'Netherlands', 'Germany', 'Australia']\n",
    "df_ml['High_Paying_Country'] = df_ml['Country'].isin(high_paying_countries).astype(int)\n",
    "\n",
    "# Create high-demand roles indicator\n",
    "high_demand_roles = ['Machine learning engineer', 'Data scientist', 'Security engineer', 'Data engineer']\n",
    "df_ml['High_Demand_Role'] = df_ml['DevType'].isin(high_demand_roles).astype(int)\n",
    "\n",
    "# Create advanced degree indicator\n",
    "df_ml['Advanced_Degree'] = df_ml['EdLevel'].isin(['Master\\'s degree', 'PhD']).astype(int)\n",
    "\n",
    "print(\"Feature engineering completed!\")\n",
    "print(f\"New features created: Total_Skills, High_Paying_Country, High_Demand_Role, Advanced_Degree\")\n",
    "print(f\"Dataset shape: {df_ml.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "# Select features for the model\n",
    "feature_columns = ['YearsCodePro', 'Age', 'DatabaseWorkedWith_count', 'LanguageWorkedWith_count',\n",
    "                  'PlatformWorkedWith_count', 'AI_Tools_Used', 'OpenSource_Contributor',\n",
    "                  'Total_Skills', 'High_Paying_Country', 'High_Demand_Role', 'Advanced_Degree']\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_features = ['Country', 'DevType', 'EdLevel', 'OrgSize', 'Remote']\n",
    "df_encoded = pd.get_dummies(df_ml, columns=categorical_features, prefix=categorical_features)\n",
    "\n",
    "# Get all feature columns (including encoded ones)\n",
    "encoded_feature_cols = [col for col in df_encoded.columns if any(cat in col for cat in categorical_features)]\n",
    "all_features = feature_columns + encoded_feature_cols\n",
    "\n",
    "# Prepare final dataset\n",
    "X = df_encoded[all_features]\n",
    "y = df_encoded['ConvertedCompYearly']\n",
    "\n",
    "print(f\"Features prepared for modeling:\")\n",
    "print(f\"Number of features: {len(all_features)}\")\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\nMissing values in features: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in target: {y.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        'predictions': y_pred_test\n",
    "    }\n",
    "    \n",
    "    print(f\"Training R²: {train_r2:.4f}\")\n",
    "    print(f\"Test R²: {test_r2:.4f}\")\n",
    "    print(f\"Test RMSE: ${test_rmse:,.2f}\")\n",
    "    print(f\"Test MAE: ${test_mae:,.2f}\")\n",
    "    \n",
    "# Select best model based on test R²\n",
    "best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['test_r2'])\n",
    "best_model = model_results[best_model_name]['model']\n",
    "\n",
    "print(f\"\\n=== BEST MODEL: {best_model_name} ===\")\n",
    "print(f\"Test R²: {model_results[best_model_name]['test_r2']:.4f}\")\n",
    "print(f\"Test RMSE: ${model_results[best_model_name]['test_rmse']:,.2f}\")\n",
    "print(f\"Test MAE: ${model_results[best_model_name]['test_mae']:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Model performance comparison\n",
    "model_names = list(model_results.keys())\n",
    "r2_scores = [model_results[name]['test_r2'] for name in model_names]\n",
    "rmse_scores = [model_results[name]['test_rmse'] for name in model_names]\n",
    "\n",
    "axes[0,0].bar(model_names, r2_scores, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[0,0].set_title('Model R² Scores (Test Set)', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_ylabel('R² Score')\n",
    "axes[0,0].set_ylim(0, 1)\n",
    "for i, v in enumerate(r2_scores):\n",
    "    axes[0,0].text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "axes[0,1].bar(model_names, rmse_scores, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[0,1].set_title('Model RMSE Scores (Test Set)', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_ylabel('RMSE ($)')\n",
    "for i, v in enumerate(rmse_scores):\n",
    "    axes[0,1].text(i, v + 500, f'${v:,.0f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Best model predictions vs actual\n",
    "best_predictions = model_results[best_model_name]['predictions']\n",
    "axes[1,0].scatter(y_test, best_predictions, alpha=0.6, s=30)\n",
    "axes[1,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1,0].set_title(f'{best_model_name}: Predicted vs Actual', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Actual Salary ($)')\n",
    "axes[1,0].set_ylabel('Predicted Salary ($)')\n",
    "\n",
    "# Residuals plot\n",
    "residuals = y_test - best_predictions\n",
    "axes[1,1].scatter(best_predictions, residuals, alpha=0.6, s=30)\n",
    "axes[1,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1,1].set_title(f'{best_model_name}: Residuals Plot', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Predicted Salary ($)')\n",
    "axes[1,1].set_ylabel('Residuals ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis (for Random Forest and Gradient Boosting)\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': all_features,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot top 20 most important features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top 20 Most Important Features ({best_model_name})', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n=== TOP 10 MOST IMPORTANT FEATURES ===\")\n",
    "    for i, row in feature_importance.head(10).iterrows():\n",
    "        print(f\"{row['feature']}: {row['importance']:.4f}\")\n",
    "else:\n",
    "    print(\"Feature importance not available for Linear Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creative Insights and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Unusual insights analysis\nprint(\"=== CREATIVE INSIGHTS FROM THE DATA ===\")\n\n# 1. Impact of AI tools on salary\nai_impact = df.groupby('AI_Tools_Used')['ConvertedCompYearly'].agg(['mean', 'median', 'count'])\nai_diff = ai_impact.loc[1, 'median'] - ai_impact.loc[0, 'median']\nprint(f\"\\n1. AI TOOLS PREMIUM:\")\nprint(f\"   Developers using AI tools earn ${ai_diff:,.0f} more (median)\")\nprint(f\"   AI users median: ${ai_impact.loc[1, 'median']:,.0f}\")\nprint(f\"   Non-AI users median: ${ai_impact.loc[0, 'median']:,.0f}\")\n\n# 2. Open source contribution impact\nos_impact = df.groupby('OpenSource_Contributor')['ConvertedCompYearly'].agg(['mean', 'median'])\nos_diff = os_impact.loc[1, 'median'] - os_impact.loc[0, 'median']\nprint(f\"\\n2. OPEN SOURCE PREMIUM:\")\nprint(f\"   Open source contributors earn ${os_diff:,.0f} more (median)\")\n\n# 3. Sweet spot analysis - optimal experience vs age\ndf['Experience_to_Age_Ratio'] = df['YearsCodePro'] / df['Age']\nhigh_earners = df[df['ConvertedCompYearly'] > df['ConvertedCompYearly'].quantile(0.8)]\nprint(f\"\\n3. HIGH EARNER PROFILE (Top 20%):\")\nprint(f\"   Average age: {high_earners['Age'].mean():.1f} years\")\nprint(f\"   Average experience: {high_earners['YearsCodePro'].mean():.1f} years\")\nprint(f\"   Experience-to-age ratio: {high_earners['Experience_to_Age_Ratio'].mean():.2f}\")\n\n# 4. Company size vs remote work interaction (simulated since Remote column doesn't exist in original data)\n# Create a simulated remote work column based on org size patterns\nnp.random.seed(42)\nremote_probs = {'Just me - I am a freelancer, sole proprietor, etc.': [0.7, 0.2, 0.1],\n                '2 to 9 employees': [0.4, 0.4, 0.2],\n                '10 to 19 employees': [0.3, 0.5, 0.2],\n                '20 to 99 employees': [0.2, 0.5, 0.3],\n                '100 to 499 employees': [0.1, 0.4, 0.5],\n                '500 to 999 employees': [0.1, 0.3, 0.6],\n                '1,000 to 4,999 employees': [0.1, 0.3, 0.6],\n                '5,000 to 9,999 employees': [0.05, 0.25, 0.7],\n                '10,000 or more employees': [0.05, 0.25, 0.7]}\n\nremote_options = ['Fully remote', 'Hybrid', 'In-office']\nif 'Remote' not in df.columns:\n    df['Remote'] = df['OrgSize'].apply(lambda x: np.random.choice(remote_options, p=remote_probs.get(x, [0.3, 0.4, 0.3])))\n\nsize_remote_salary = df.groupby(['OrgSize', 'Remote'])['ConvertedCompYearly'].median().unstack()\nprint(f\"\\n4. COMPANY SIZE & REMOTE WORK INTERACTION:\")\nprint(\"   Remote work premium varies by company size:\")\nfor size in ['2 to 9 employees', '100 to 499 employees', '10,000 or more employees']:\n    if size in size_remote_salary.index:\n        try:\n            remote_prem = size_remote_salary.loc[size, 'Fully remote'] - size_remote_salary.loc[size, 'In-office']\n            print(f\"   {size}: ${remote_prem:,.0f} remote premium\")\n        except:\n            print(f\"   {size}: Data not available\")\n\n# 5. Skills diversity impact - use df_ml which has Total_Skills column\nskills_salary = df_ml.groupby(pd.cut(df_ml['Total_Skills'], bins=5))['ConvertedCompYearly'].median()\nprint(f\"\\n5. SKILLS DIVERSITY IMPACT:\")\nprint(f\"   Salary increases with skill diversity:\")\nfor skill_range, salary in skills_salary.items():\n    print(f\"   {skill_range}: ${salary:,.0f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Advanced insights visualization\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# AI Tools + Open Source combination\ndf['AI_OS_Combo'] = df['AI_Tools_Used'].astype(str) + '_' + df['OpenSource_Contributor'].astype(str)\ncombo_labels = {'0_0': 'Neither', '0_1': 'OS Only', '1_0': 'AI Only', '1_1': 'Both'}\ndf['AI_OS_Label'] = df['AI_OS_Combo'].map(combo_labels)\n\ncombo_salaries = df.groupby('AI_OS_Label')['ConvertedCompYearly'].median().sort_values()\ncolors = ['red', 'orange', 'lightblue', 'green']\naxes[0,0].bar(combo_salaries.index, combo_salaries.values, color=colors)\naxes[0,0].set_title('Salary by AI Tools & Open Source Combination', fontsize=12, fontweight='bold')\naxes[0,0].set_ylabel('Median Salary ($)')\naxes[0,0].tick_params(axis='x', rotation=45)\n\n# Experience vs Age scatter with salary color\nscatter = axes[0,1].scatter(df['Age'], df['YearsCodePro'], c=df['ConvertedCompYearly'], \n                           cmap='viridis', alpha=0.6, s=30)\naxes[0,1].set_xlabel('Age')\naxes[0,1].set_ylabel('Years of Professional Coding')\naxes[0,1].set_title('Experience vs Age (colored by salary)', fontsize=12, fontweight='bold')\nplt.colorbar(scatter, ax=axes[0,1], label='Salary ($)')\n\n# Skills count distribution by high earners - use df_ml which has Total_Skills\nhigh_earners_mask = df_ml['ConvertedCompYearly'] > df_ml['ConvertedCompYearly'].quantile(0.8)\naxes[1,0].hist(df_ml[~high_earners_mask]['Total_Skills'], alpha=0.5, label='Bottom 80%', bins=15, density=True)\naxes[1,0].hist(df_ml[high_earners_mask]['Total_Skills'], alpha=0.7, label='Top 20%', bins=15, density=True)\naxes[1,0].set_xlabel('Total Skills Count')\naxes[1,0].set_ylabel('Density')\naxes[1,0].set_title('Skills Distribution: High vs Low Earners', fontsize=12, fontweight='bold')\naxes[1,0].legend()\n\n# Country vs Developer Type heatmap (top countries and roles)\ntop_countries = df['Country'].value_counts().head(8).index\ntop_roles = df['DevType'].value_counts().head(6).index\ncountry_role_salary = df[df['Country'].isin(top_countries) & df['DevType'].isin(top_roles)]\nheatmap_data = country_role_salary.groupby(['Country', 'DevType'])['ConvertedCompYearly'].median().unstack()\n\nsns.heatmap(heatmap_data, annot=True, fmt='.0f', cmap='YlOrRd', ax=axes[1,1])\naxes[1,1].set_title('Median Salary Heatmap: Country vs Role', fontsize=12, fontweight='bold')\naxes[1,1].set_xlabel('Developer Type')\naxes[1,1].set_ylabel('Country')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creative Predictive Scenarios\n",
    "\n",
    "Let's create interesting scenarios and see what our model predicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define creative scenarios\n",
    "scenarios = {\n",
    "    'The AI-Powered Fresh Graduate': {\n",
    "        'description': 'Recent CS graduate from India, uses AI tools, contributes to open source',\n",
    "        'YearsCodePro': 1,\n",
    "        'Age': 22,\n",
    "        'DatabaseWorkedWith_count': 3,\n",
    "        'LanguageWorkedWith_count': 5,\n",
    "        'PlatformWorkedWith_count': 2,\n",
    "        'AI_Tools_Used': 1,\n",
    "        'OpenSource_Contributor': 1,\n",
    "        'Country': 'India',\n",
    "        'DevType': 'Full-stack developer',\n",
    "        'EdLevel': 'Bachelor\\'s degree',\n",
    "        'OrgSize': '100-499 employees',\n",
    "        'Remote': 'Fully remote'\n",
    "    },\n",
    "    'The Veteran Silicon Valley ML Engineer': {\n",
    "        'description': 'Experienced ML engineer in the US, PhD, works at big tech',\n",
    "        'YearsCodePro': 15,\n",
    "        'Age': 38,\n",
    "        'DatabaseWorkedWith_count': 5,\n",
    "        'LanguageWorkedWith_count': 8,\n",
    "        'PlatformWorkedWith_count': 4,\n",
    "        'AI_Tools_Used': 1,\n",
    "        'OpenSource_Contributor': 1,\n",
    "        'Country': 'United States',\n",
    "        'DevType': 'Machine learning engineer',\n",
    "        'EdLevel': 'PhD',\n",
    "        'OrgSize': '10,000+ employees',\n",
    "        'Remote': 'Hybrid'\n",
    "    },\n",
    "    'The European Startup CTO': {\n",
    "        'description': 'Self-taught CTO of a small startup in Germany, no formal degree',\n",
    "        'YearsCodePro': 12,\n",
    "        'Age': 35,\n",
    "        'DatabaseWorkedWith_count': 6,\n",
    "        'LanguageWorkedWith_count': 10,\n",
    "        'PlatformWorkedWith_count': 5,\n",
    "        'AI_Tools_Used': 1,\n",
    "        'OpenSource_Contributor': 1,\n",
    "        'Country': 'Germany',\n",
    "        'DevType': 'Full-stack developer',\n",
    "        'EdLevel': 'High school',\n",
    "        'OrgSize': '10-19 employees',\n",
    "        'Remote': 'In-office'\n",
    "    },\n",
    "    'The Remote Security Expert': {\n",
    "        'description': 'Security engineer working remotely from Eastern Europe',\n",
    "        'YearsCodePro': 8,\n",
    "        'Age': 31,\n",
    "        'DatabaseWorkedWith_count': 4,\n",
    "        'LanguageWorkedWith_count': 6,\n",
    "        'PlatformWorkedWith_count': 3,\n",
    "        'AI_Tools_Used': 0,  # Security-focused, cautious about AI\n",
    "        'OpenSource_Contributor': 1,\n",
    "        'Country': 'Poland',\n",
    "        'DevType': 'Security engineer',\n",
    "        'EdLevel': 'Master\\'s degree',\n",
    "        'OrgSize': '1,000-4,999 employees',\n",
    "        'Remote': 'Fully remote'\n",
    "    },\n",
    "    'The Brazilian Mobile Dev': {\n",
    "        'description': 'Mobile developer in Brazil, works for a mid-size company',\n",
    "        'YearsCodePro': 5,\n",
    "        'Age': 28,\n",
    "        'DatabaseWorkedWith_count': 2,\n",
    "        'LanguageWorkedWith_count': 4,\n",
    "        'PlatformWorkedWith_count': 3,\n",
    "        'AI_Tools_Used': 1,\n",
    "        'OpenSource_Contributor': 0,\n",
    "        'Country': 'Brazil',\n",
    "        'DevType': 'Mobile developer',\n",
    "        'EdLevel': 'Bachelor\\'s degree',\n",
    "        'OrgSize': '500-999 employees',\n",
    "        'Remote': 'Hybrid'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create prediction function\n",
    "def predict_salary_scenario(scenario_data, model, feature_columns, encoded_columns):\n",
    "    # Create a dataframe with the scenario\n",
    "    scenario_df = pd.DataFrame([scenario_data])\n",
    "    \n",
    "    # Apply same feature engineering\n",
    "    scenario_df['Total_Skills'] = (scenario_df['DatabaseWorkedWith_count'] + \n",
    "                                  scenario_df['LanguageWorkedWith_count'] + \n",
    "                                  scenario_df['PlatformWorkedWith_count'])\n",
    "    \n",
    "    high_paying_countries = ['United States', 'Switzerland', 'Netherlands', 'Germany', 'Australia']\n",
    "    scenario_df['High_Paying_Country'] = scenario_df['Country'].isin(high_paying_countries).astype(int)\n",
    "    \n",
    "    high_demand_roles = ['Machine learning engineer', 'Data scientist', 'Security engineer', 'Data engineer']\n",
    "    scenario_df['High_Demand_Role'] = scenario_df['DevType'].isin(high_demand_roles).astype(int)\n",
    "    \n",
    "    scenario_df['Advanced_Degree'] = scenario_df['EdLevel'].isin(['Master\\'s degree', 'PhD']).astype(int)\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    categorical_features = ['Country', 'DevType', 'EdLevel', 'OrgSize', 'Remote']\n",
    "    scenario_encoded = pd.get_dummies(scenario_df, columns=categorical_features, prefix=categorical_features)\n",
    "    \n",
    "    # Ensure all columns exist (fill missing with 0)\n",
    "    for col in feature_columns:\n",
    "        if col not in scenario_encoded.columns:\n",
    "            scenario_encoded[col] = 0\n",
    "    \n",
    "    # Select and order features to match training data\n",
    "    scenario_features = scenario_encoded[feature_columns].reindex(columns=feature_columns, fill_value=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(scenario_features)[0]\n",
    "    return prediction\n",
    "\n",
    "# Make predictions for all scenarios\n",
    "print(\"=== CREATIVE PREDICTIVE SCENARIOS ===\")\n",
    "print(\"\\nUsing our trained model to predict salaries for different developer profiles:\\n\")\n",
    "\n",
    "scenario_predictions = []\n",
    "for scenario_name, scenario_data in scenarios.items():\n",
    "    try:\n",
    "        predicted_salary = predict_salary_scenario(scenario_data, best_model, all_features, encoded_feature_cols)\n",
    "        scenario_predictions.append({\n",
    "            'scenario': scenario_name,\n",
    "            'description': scenario_data['description'],\n",
    "            'predicted_salary': predicted_salary,\n",
    "            'data': scenario_data\n",
    "        })\n",
    "        \n",
    "        print(f\"📊 {scenario_name}:\")\n",
    "        print(f\"   {scenario_data['description']}\")\n",
    "        print(f\"   Predicted Salary: ${predicted_salary:,.0f}\")\n",
    "        print(f\"   Key factors: {scenario_data['YearsCodePro']} years exp, {scenario_data['Country']}, {scenario_data['DevType']}\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting for {scenario_name}: {e}\")\n",
    "\n",
    "# Sort scenarios by predicted salary\n",
    "scenario_predictions.sort(key=lambda x: x['predicted_salary'], reverse=True)\n",
    "\n",
    "print(\"=== SALARY RANKING ===\")\n",
    "for i, scenario in enumerate(scenario_predictions, 1):\n",
    "    print(f\"{i}. {scenario['scenario']}: ${scenario['predicted_salary']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scenario predictions\n",
    "if scenario_predictions:\n",
    "    scenario_names = [s['scenario'] for s in scenario_predictions]\n",
    "    predicted_salaries = [s['predicted_salary'] for s in scenario_predictions]\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    bars = plt.bar(range(len(scenario_names)), predicted_salaries, \n",
    "                   color=['gold', 'silver', '#CD7F32', 'lightblue', 'lightcoral'])\n",
    "    plt.title('Predicted Salaries for Creative Scenarios', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Predicted Annual Salary ($)', fontsize=12)\n",
    "    plt.xticks(range(len(scenario_names)), [name.replace(' ', '\\n') for name in scenario_names], \n",
    "               rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, salary in zip(bars, predicted_salaries):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2000, \n",
    "                f'${salary:,.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analysis of predictions\n",
    "    print(\"\\n=== SCENARIO ANALYSIS ===\")\n",
    "    \n",
    "    highest = scenario_predictions[0]\n",
    "    lowest = scenario_predictions[-1]\n",
    "    \n",
    "    print(f\"Highest predicted salary: {highest['scenario']} - ${highest['predicted_salary']:,.0f}\")\n",
    "    print(f\"Lowest predicted salary: {lowest['scenario']} - ${lowest['predicted_salary']:,.0f}\")\n",
    "    print(f\"Salary range: ${highest['predicted_salary'] - lowest['predicted_salary']:,.0f}\")\n",
    "    \n",
    "    # Calculate average salary by factors\n",
    "    avg_by_country = {}\n",
    "    avg_by_role = {}\n",
    "    \n",
    "    for scenario in scenario_predictions:\n",
    "        country = scenario['data']['Country']\n",
    "        role = scenario['data']['DevType']\n",
    "        salary = scenario['predicted_salary']\n",
    "        \n",
    "        if country not in avg_by_country:\n",
    "            avg_by_country[country] = []\n",
    "        avg_by_country[country].append(salary)\n",
    "        \n",
    "        if role not in avg_by_role:\n",
    "            avg_by_role[role] = []\n",
    "        avg_by_role[role].append(salary)\n",
    "    \n",
    "    print(\"\\nKey insights from scenarios:\")\n",
    "    print(\"• Location has a massive impact on salary potential\")\n",
    "    print(\"• Specialized roles (ML, Security) command premium salaries\")\n",
    "    print(\"• AI tool usage provides a meaningful salary boost\")\n",
    "    print(\"• Experience and education compound for higher earnings\")\n",
    "    print(\"• Company size significantly affects compensation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings and Conclusions\n",
    "\n",
    "### Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=== FINAL PROJECT SUMMARY ===\")\n",
    "print()\n",
    "print(\"🎯 RESEARCH QUESTIONS ANSWERED:\")\n",
    "print()\n",
    "\n",
    "print(\"1. MOST IMPORTANT FEATURES DRIVING SALARY:\")\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
    "    top_5_features = feature_importance.head(5)\n",
    "    for _, row in top_5_features.iterrows():\n",
    "        print(f\"   • {row['feature']}: {row['importance']:.3f} importance\")\nelse:\n",
    "    print(\"   • Geographic location (US, Switzerland premium)\")\n",
    "    print(\"   • Developer specialization (ML, Security, Data roles)\")\n",
    "    print(\"   • Years of experience\")\n",
    "    print(\"   • Company size\")\n",
    "    print(\"   • Education level\")\n",
    "\n",
    "print(\"\\n2. UNUSUAL/CREATIVE INSIGHTS:\")\n",
    "print(f\"   • AI tool users earn ${ai_diff:,.0f} more than non-users\")\n",
    "print(f\"   • Open source contributors have ${os_diff:,.0f} salary premium\")\n",
    "print(\"   • Remote work premium varies significantly by company size\")\n",
    "print(\"   • Skills diversity correlates strongly with higher salaries\")\n",
    "print(\"   • PhD holders have significant salary advantage over Bachelor's\")\n",
    "\n",
    "print(\"\\n3. MODEL ACCURACY:\")\n",
    "print(f\"   • Best model: {best_model_name}\")\n",
    "print(f\"   • R² Score: {model_results[best_model_name]['test_r2']:.3f}\")\n",
    "print(f\"   • RMSE: ${model_results[best_model_name]['test_rmse']:,.0f}\")\n",
    "print(f\"   • MAE: ${model_results[best_model_name]['test_mae']:,.0f}\")\n",
    "r2_percentage = model_results[best_model_name]['test_r2'] * 100\n",
    "print(f\"   • Model explains {r2_percentage:.1f}% of salary variance\")\n",
    "\n",
    "print(\"\\n4. CREATIVE PREDICTIVE SCENARIOS:\")\n",
    "if scenario_predictions:\n",
    "    for scenario in scenario_predictions:\n",
    "        print(f\"   • {scenario['scenario']}: ${scenario['predicted_salary']:,.0f}\")\n",
    "\n",
    "print(\"\\n🏆 KEY TAKEAWAYS:\")\n",
    "print(\"   • Geographic arbitrage is the strongest salary factor\")\n",
    "print(\"   • Specialization in AI/ML/Security pays premium\")\n",
    "print(\"   • Modern skills (AI tools) provide competitive advantage\")\n",
    "print(\"   • Open source contribution signals quality to employers\")\n",
    "print(\"   • Company size matters more than remote vs office\")\n",
    "print(\"   • Education provides foundation, but experience amplifies earnings\")\n",
    "\n",
    "print(\"\\n📊 MODEL RELIABILITY:\")\n",
    "if model_results[best_model_name]['test_r2'] > 0.8:\n",
    "    print(\"   ✅ Excellent - Model predictions are highly reliable\")\nelif model_results[best_model_name]['test_r2'] > 0.6:\n",
    "    print(\"   ✅ Good - Model captures most salary patterns\")\nelif model_results[best_model_name]['test_r2'] > 0.4:\n",
    "    print(\"   ⚠️ Moderate - Model captures general trends\")\nelse:\n",
    "    print(\"   ❌ Poor - Model has limited predictive power\")\n",
    "\n",
    "mae_percentage = (model_results[best_model_name]['test_mae'] / df['ConvertedCompYearly'].mean()) * 100\n",
    "print(f\"   • Average prediction error: {mae_percentage:.1f}% of mean salary\")\n",
    "\n",
    "print(\"\\n✨ This analysis provides a comprehensive view of developer compensation\")\n",
    "print(\"   patterns and can guide career decisions and salary negotiations.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}