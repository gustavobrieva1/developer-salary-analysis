{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developer Salary Analysis: What Drives Compensation in Tech?\n",
    "\n",
    "## Project Overview\n",
    "This analysis explores factors that influence developer salaries based on survey data similar to the StackOverflow Developer Survey. We aim to answer:\n",
    "\n",
    "1. **What are the most important features that drive developer salaries?**\n",
    "2. **What unusual insights can we discover about developer compensation patterns?**\n",
    "3. **How accurately can we predict salaries using machine learning?**\n",
    "4. **What would happen in creative predictive scenarios?**\n",
    "\n",
    "## Business Questions\n",
    "- Which technologies and skills command the highest salaries?\n",
    "- How do experience, education, and location impact compensation?\n",
    "- Can we predict salary ranges for different developer profiles?\n",
    "- What career paths lead to the highest earning potential?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation and Loading\n",
    "\n",
    "Since we're creating a representative dataset based on real-world developer survey patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic developer data based on real survey patterns\n",
    "n_samples = 5000\n",
    "\n",
    "# Define realistic value ranges\n",
    "countries = ['United States', 'Germany', 'United Kingdom', 'Canada', 'Australia', \n",
    "            'Netherlands', 'Sweden', 'France', 'Switzerland', 'India', 'Brazil', \n",
    "            'Poland', 'Russia', 'Spain', 'Italy']\n",
    "\n",
    "dev_types = ['Full-stack developer', 'Back-end developer', 'Front-end developer', \n",
    "            'Data scientist', 'DevOps engineer', 'Mobile developer', 'QA engineer',\n",
    "            'Data engineer', 'Machine learning engineer', 'Security engineer']\n",
    "\n",
    "education_levels = ['Bachelor\\'s degree', 'Master\\'s degree', 'Some college', \n",
    "                   'High school', 'PhD', 'Professional certificate']\n",
    "\n",
    "company_sizes = ['2-9 employees', '10-19 employees', '20-99 employees', \n",
    "                '100-499 employees', '500-999 employees', '1,000-4,999 employees', \n",
    "                '5,000-9,999 employees', '10,000+ employees']\n",
    "\n",
    "# Generate data\n",
    "data = {\n",
    "    'Country': np.random.choice(countries, n_samples, \n",
    "                               p=[0.25, 0.08, 0.07, 0.06, 0.05, 0.04, 0.04, 0.04, 0.03, \n",
    "                                 0.15, 0.06, 0.03, 0.03, 0.03, 0.04]),\n",
    "    \n",
    "    'DevType': np.random.choice(dev_types, n_samples,\n",
    "                               p=[0.20, 0.18, 0.15, 0.12, 0.10, 0.08, 0.06, 0.05, 0.04, 0.02]),\n",
    "    \n",
    "    'YearsCodePro': np.random.exponential(scale=3, size=n_samples).astype(int),\n",
    "    \n",
    "    'EdLevel': np.random.choice(education_levels, n_samples,\n",
    "                               p=[0.45, 0.25, 0.12, 0.08, 0.06, 0.04]),\n",
    "    \n",
    "    'OrgSize': np.random.choice(company_sizes, n_samples,\n",
    "                               p=[0.08, 0.10, 0.18, 0.22, 0.12, 0.15, 0.08, 0.07]),\n",
    "    \n",
    "    'Remote': np.random.choice(['Fully remote', 'Hybrid', 'In-office'], n_samples,\n",
    "                              p=[0.35, 0.45, 0.20]),\n",
    "    \n",
    "    'Age': np.random.normal(32, 8, n_samples).astype(int),\n",
    "    \n",
    "    'DatabaseWorkedWith_count': np.random.poisson(3, n_samples),\n",
    "    'LanguageWorkedWith_count': np.random.poisson(4, n_samples),\n",
    "    'PlatformWorkedWith_count': np.random.poisson(2, n_samples),\n",
    "    \n",
    "    'AI_Tools_Used': np.random.choice([0, 1], n_samples, p=[0.35, 0.65]),\n",
    "    'OpenSource_Contributor': np.random.choice([0, 1], n_samples, p=[0.60, 0.40])\n",
    "}\n",
    "\n",
    "# Create base salary calculation with realistic factors\n",
    "base_salary = 50000\n",
    "country_multiplier = {\n",
    "    'United States': 1.4, 'Switzerland': 1.6, 'Germany': 1.1, 'United Kingdom': 1.2,\n",
    "    'Canada': 1.1, 'Australia': 1.2, 'Netherlands': 1.3, 'Sweden': 1.2,\n",
    "    'France': 1.0, 'India': 0.3, 'Brazil': 0.4, 'Poland': 0.6,\n",
    "    'Russia': 0.5, 'Spain': 0.8, 'Italy': 0.8\n",
    "}\n",
    "\n",
    "role_multiplier = {\n",
    "    'Machine learning engineer': 1.5, 'Data scientist': 1.4, 'Security engineer': 1.4,\n",
    "    'Data engineer': 1.3, 'DevOps engineer': 1.3, 'Full-stack developer': 1.2,\n",
    "    'Back-end developer': 1.15, 'Front-end developer': 1.0, 'Mobile developer': 1.1,\n",
    "    'QA engineer': 0.9\n",
    "}\n",
    "\n",
    "education_bonus = {\n",
    "    'PhD': 1.3, 'Master\\'s degree': 1.15, 'Bachelor\\'s degree': 1.0,\n",
    "    'Professional certificate': 0.95, 'Some college': 0.85, 'High school': 0.75\n",
    "}\n",
    "\n",
    "# Calculate salaries with realistic factors\n",
    "salaries = []\n",
    "for i in range(n_samples):\n",
    "    country_mult = country_multiplier[data['Country'][i]]\n",
    "    role_mult = role_multiplier[data['DevType'][i]]\n",
    "    edu_mult = education_bonus[data['EdLevel'][i]]\n",
    "    \n",
    "    experience_mult = 1 + (data['YearsCodePro'][i] * 0.05)  # 5% per year\n",
    "    age_factor = 1 + ((data['Age'][i] - 25) * 0.01)  # Age premium\n",
    "    skills_bonus = 1 + (data['LanguageWorkedWith_count'][i] * 0.02)  # Skills bonus\n",
    "    ai_bonus = 1.1 if data['AI_Tools_Used'][i] else 1.0\n",
    "    opensource_bonus = 1.05 if data['OpenSource_Contributor'][i] else 1.0\n",
    "    \n",
    "    # Company size effect\n",
    "    size_multiplier = {'2-9 employees': 0.8, '10-19 employees': 0.85,\n",
    "                      '20-99 employees': 0.9, '100-499 employees': 0.95,\n",
    "                      '500-999 employees': 1.0, '1,000-4,999 employees': 1.1,\n",
    "                      '5,000-9,999 employees': 1.15, '10,000+ employees': 1.2}\n",
    "    \n",
    "    size_mult = size_multiplier[data['OrgSize'][i]]\n",
    "    \n",
    "    # Remote work adjustment\n",
    "    remote_mult = {'Fully remote': 1.05, 'Hybrid': 1.02, 'In-office': 1.0}[data['Remote'][i]]\n",
    "    \n",
    "    salary = (base_salary * country_mult * role_mult * edu_mult * \n",
    "             experience_mult * age_factor * skills_bonus * size_mult * \n",
    "             ai_bonus * opensource_bonus * remote_mult)\n",
    "    \n",
    "    # Add some noise\n",
    "    salary *= np.random.normal(1, 0.15)\n",
    "    \n",
    "    # Cap negative values and extreme outliers\n",
    "    salary = max(25000, min(500000, salary))\n",
    "    \n",
    "    salaries.append(int(salary))\n",
    "\n",
    "data['ConvertedCompYearly'] = salaries\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Clean up unrealistic combinations\n",
    "df = df[(df['Age'] >= 18) & (df['Age'] <= 65)]\n",
    "df = df[df['YearsCodePro'] <= 40]\n",
    "df = df[df['YearsCodePro'] <= df['Age'] - 16]  # Can't code professionally before ~16\n",
    "\n",
    "print(f\"Dataset created with {len(df)} records\")\n",
    "print(f\"Salary range: ${df['ConvertedCompYearly'].min():,} - ${df['ConvertedCompYearly'].max():,}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's explore the structure and patterns in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary distribution analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Salary histogram\n",
    "axes[0,0].hist(df['ConvertedCompYearly'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Distribution of Annual Salaries', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_xlabel('Annual Salary ($)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].axvline(df['ConvertedCompYearly'].mean(), color='red', linestyle='--', \n",
    "                  label=f'Mean: ${df[\"ConvertedCompYearly\"].mean():,.0f}')\n",
    "axes[0,0].axvline(df['ConvertedCompYearly'].median(), color='green', linestyle='--', \n",
    "                  label=f'Median: ${df[\"ConvertedCompYearly\"].median():,.0f}')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Log-transformed salary\n",
    "axes[0,1].hist(np.log(df['ConvertedCompYearly']), bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0,1].set_title('Log-Transformed Salary Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Log(Annual Salary)')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "\n",
    "# Experience vs Salary\n",
    "axes[1,0].scatter(df['YearsCodePro'], df['ConvertedCompYearly'], alpha=0.5, s=30)\n",
    "axes[1,0].set_title('Experience vs Salary', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Years of Professional Coding')\n",
    "axes[1,0].set_ylabel('Annual Salary ($)')\n",
    "\n",
    "# Age vs Salary\n",
    "axes[1,1].scatter(df['Age'], df['ConvertedCompYearly'], alpha=0.5, s=30, color='coral')\n",
    "axes[1,1].set_title('Age vs Salary', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Age')\n",
    "axes[1,1].set_ylabel('Annual Salary ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== SALARY STATISTICS ===\")\n",
    "print(f\"Mean salary: ${df['ConvertedCompYearly'].mean():,.2f}\")\n",
    "print(f\"Median salary: ${df['ConvertedCompYearly'].median():,.2f}\")\n",
    "print(f\"Standard deviation: ${df['ConvertedCompYearly'].std():,.2f}\")\n",
    "print(f\"25th percentile: ${df['ConvertedCompYearly'].quantile(0.25):,.2f}\")\n",
    "print(f\"75th percentile: ${df['ConvertedCompYearly'].quantile(0.75):,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Salary by Country (top 10)\n",
    "country_salaries = df.groupby('Country')['ConvertedCompYearly'].median().sort_values(ascending=False).head(10)\n",
    "axes[0,0].bar(range(len(country_salaries)), country_salaries.values, color='steelblue')\n",
    "axes[0,0].set_title('Median Salary by Country (Top 10)', fontsize=12, fontweight='bold')\n",
    "axes[0,0].set_xticks(range(len(country_salaries)))\n",
    "axes[0,0].set_xticklabels(country_salaries.index, rotation=45, ha='right')\n",
    "axes[0,0].set_ylabel('Median Salary ($)')\n",
    "\n",
    "# Salary by Developer Type\n",
    "role_salaries = df.groupby('DevType')['ConvertedCompYearly'].median().sort_values(ascending=False)\n",
    "axes[0,1].bar(range(len(role_salaries)), role_salaries.values, color='darkorange')\n",
    "axes[0,1].set_title('Median Salary by Developer Type', fontsize=12, fontweight='bold')\n",
    "axes[0,1].set_xticks(range(len(role_salaries)))\n",
    "axes[0,1].set_xticklabels(role_salaries.index, rotation=45, ha='right')\n",
    "axes[0,1].set_ylabel('Median Salary ($)')\n",
    "\n",
    "# Salary by Education Level\n",
    "edu_salaries = df.groupby('EdLevel')['ConvertedCompYearly'].median().sort_values(ascending=False)\n",
    "axes[0,2].bar(range(len(edu_salaries)), edu_salaries.values, color='forestgreen')\n",
    "axes[0,2].set_title('Median Salary by Education Level', fontsize=12, fontweight='bold')\n",
    "axes[0,2].set_xticks(range(len(edu_salaries)))\n",
    "axes[0,2].set_xticklabels(edu_salaries.index, rotation=45, ha='right')\n",
    "axes[0,2].set_ylabel('Median Salary ($)')\n",
    "\n",
    "# Salary by Company Size\n",
    "size_salaries = df.groupby('OrgSize')['ConvertedCompYearly'].median()\n",
    "# Reorder for logical progression\n",
    "size_order = ['2-9 employees', '10-19 employees', '20-99 employees', \n",
    "              '100-499 employees', '500-999 employees', '1,000-4,999 employees',\n",
    "              '5,000-9,999 employees', '10,000+ employees']\n",
    "size_salaries_ordered = size_salaries.reindex(size_order)\n",
    "axes[1,0].bar(range(len(size_salaries_ordered)), size_salaries_ordered.values, color='purple')\n",
    "axes[1,0].set_title('Median Salary by Company Size', fontsize=12, fontweight='bold')\n",
    "axes[1,0].set_xticks(range(len(size_salaries_ordered)))\n",
    "axes[1,0].set_xticklabels(size_salaries_ordered.index, rotation=45, ha='right')\n",
    "axes[1,0].set_ylabel('Median Salary ($)')\n",
    "\n",
    "# Salary by Remote Work\n",
    "remote_salaries = df.groupby('Remote')['ConvertedCompYearly'].median().sort_values(ascending=False)\n",
    "axes[1,1].bar(range(len(remote_salaries)), remote_salaries.values, color='teal')\n",
    "axes[1,1].set_title('Median Salary by Work Arrangement', fontsize=12, fontweight='bold')\n",
    "axes[1,1].set_xticks(range(len(remote_salaries)))\n",
    "axes[1,1].set_xticklabels(remote_salaries.index)\n",
    "axes[1,1].set_ylabel('Median Salary ($)')\n",
    "\n",
    "# AI Tools impact\n",
    "ai_salaries = df.groupby('AI_Tools_Used')['ConvertedCompYearly'].median()\n",
    "axes[1,2].bar(['No AI Tools', 'Uses AI Tools'], ai_salaries.values, color=['red', 'blue'])\n",
    "axes[1,2].set_title('Median Salary: AI Tools Usage', fontsize=12, fontweight='bold')\n",
    "axes[1,2].set_ylabel('Median Salary ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "# Prepare numerical features for correlation\n",
    "df_corr = df.copy()\n",
    "\n",
    "# Encode categorical variables for correlation analysis\n",
    "le_dict = {}\n",
    "categorical_cols = ['Country', 'DevType', 'EdLevel', 'OrgSize', 'Remote']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_corr[f'{col}_encoded'] = le.fit_transform(df_corr[col])\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Select numerical columns for correlation\n",
    "numerical_cols = ['YearsCodePro', 'Age', 'DatabaseWorkedWith_count', 'LanguageWorkedWith_count',\n",
    "                 'PlatformWorkedWith_count', 'AI_Tools_Used', 'OpenSource_Contributor', 'ConvertedCompYearly']\n",
    "encoded_cols = [f'{col}_encoded' for col in categorical_cols]\n",
    "\n",
    "correlation_data = df_corr[numerical_cols + encoded_cols]\n",
    "\n",
    "# Create correlation matrix\n",
    "plt.figure(figsize=(14, 10))\n",
    "correlation_matrix = correlation_data.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .5})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show strongest correlations with salary\n",
    "salary_correlations = correlation_matrix['ConvertedCompYearly'].abs().sort_values(ascending=False)[1:]\n",
    "print(\"\\n=== STRONGEST CORRELATIONS WITH SALARY ===\")\n",
    "for feature, corr in salary_correlations.head(10).items():\n",
    "    print(f\"{feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df_ml = df.copy()\n",
    "\n",
    "# Create experience bins\n",
    "df_ml['Experience_Level'] = pd.cut(df_ml['YearsCodePro'], \n",
    "                                  bins=[0, 2, 5, 10, 20, 50], \n",
    "                                  labels=['Junior', 'Mid-level', 'Senior', 'Lead', 'Executive'])\n",
    "\n",
    "# Create age groups\n",
    "df_ml['Age_Group'] = pd.cut(df_ml['Age'], \n",
    "                           bins=[0, 25, 35, 45, 100], \n",
    "                           labels=['Young', 'Mid-career', 'Experienced', 'Veteran'])\n",
    "\n",
    "# Create total skills count\n",
    "df_ml['Total_Skills'] = (df_ml['DatabaseWorkedWith_count'] + \n",
    "                        df_ml['LanguageWorkedWith_count'] + \n",
    "                        df_ml['PlatformWorkedWith_count'])\n",
    "\n",
    "# Create high-paying countries indicator\n",
    "high_paying_countries = ['United States', 'Switzerland', 'Netherlands', 'Germany', 'Australia']\n",
    "df_ml['High_Paying_Country'] = df_ml['Country'].isin(high_paying_countries).astype(int)\n",
    "\n",
    "# Create high-demand roles indicator\n",
    "high_demand_roles = ['Machine learning engineer', 'Data scientist', 'Security engineer', 'Data engineer']\n",
    "df_ml['High_Demand_Role'] = df_ml['DevType'].isin(high_demand_roles).astype(int)\n",
    "\n",
    "# Create advanced degree indicator\n",
    "df_ml['Advanced_Degree'] = df_ml['EdLevel'].isin(['Master\\'s degree', 'PhD']).astype(int)\n",
    "\n",
    "print(\"Feature engineering completed!\")\n",
    "print(f\"New features created: Total_Skills, High_Paying_Country, High_Demand_Role, Advanced_Degree\")\n",
    "print(f\"Dataset shape: {df_ml.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "# Select features for the model\n",
    "feature_columns = ['YearsCodePro', 'Age', 'DatabaseWorkedWith_count', 'LanguageWorkedWith_count',\n",
    "                  'PlatformWorkedWith_count', 'AI_Tools_Used', 'OpenSource_Contributor',\n",
    "                  'Total_Skills', 'High_Paying_Country', 'High_Demand_Role', 'Advanced_Degree']\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_features = ['Country', 'DevType', 'EdLevel', 'OrgSize', 'Remote']\n",
    "df_encoded = pd.get_dummies(df_ml, columns=categorical_features, prefix=categorical_features)\n",
    "\n",
    "# Get all feature columns (including encoded ones)\n",
    "encoded_feature_cols = [col for col in df_encoded.columns if any(cat in col for cat in categorical_features)]\n",
    "all_features = feature_columns + encoded_feature_cols\n",
    "\n",
    "# Prepare final dataset\n",
    "X = df_encoded[all_features]\n",
    "y = df_encoded['ConvertedCompYearly']\n",
    "\n",
    "print(f\"Features prepared for modeling:\")\n",
    "print(f\"Number of features: {len(all_features)}\")\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\nMissing values in features: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in target: {y.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        'predictions': y_pred_test\n",
    "    }\n",
    "    \n",
    "    print(f\"Training R²: {train_r2:.4f}\")\n",
    "    print(f\"Test R²: {test_r2:.4f}\")\n",
    "    print(f\"Test RMSE: ${test_rmse:,.2f}\")\n",
    "    print(f\"Test MAE: ${test_mae:,.2f}\")\n",
    "    \n",
    "# Select best model based on test R²\n",
    "best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['test_r2'])\n",
    "best_model = model_results[best_model_name]['model']\n",
    "\n",
    "print(f\"\\n=== BEST MODEL: {best_model_name} ===\")\n",
    "print(f\"Test R²: {model_results[best_model_name]['test_r2']:.4f}\")\n",
    "print(f\"Test RMSE: ${model_results[best_model_name]['test_rmse']:,.2f}\")\n",
    "print(f\"Test MAE: ${model_results[best_model_name]['test_mae']:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Model performance comparison\n",
    "model_names = list(model_results.keys())\n",
    "r2_scores = [model_results[name]['test_r2'] for name in model_names]\n",
    "rmse_scores = [model_results[name]['test_rmse'] for name in model_names]\n",
    "\n",
    "axes[0,0].bar(model_names, r2_scores, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[0,0].set_title('Model R² Scores (Test Set)', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_ylabel('R² Score')\n",
    "axes[0,0].set_ylim(0, 1)\n",
    "for i, v in enumerate(r2_scores):\n",
    "    axes[0,0].text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "axes[0,1].bar(model_names, rmse_scores, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[0,1].set_title('Model RMSE Scores (Test Set)', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_ylabel('RMSE ($)')\n",
    "for i, v in enumerate(rmse_scores):\n",
    "    axes[0,1].text(i, v + 500, f'${v:,.0f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Best model predictions vs actual\n",
    "best_predictions = model_results[best_model_name]['predictions']\n",
    "axes[1,0].scatter(y_test, best_predictions, alpha=0.6, s=30)\n",
    "axes[1,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1,0].set_title(f'{best_model_name}: Predicted vs Actual', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Actual Salary ($)')\n",
    "axes[1,0].set_ylabel('Predicted Salary ($)')\n",
    "\n",
    "# Residuals plot\n",
    "residuals = y_test - best_predictions\n",
    "axes[1,1].scatter(best_predictions, residuals, alpha=0.6, s=30)\n",
    "axes[1,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1,1].set_title(f'{best_model_name}: Residuals Plot', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Predicted Salary ($)')\n",
    "axes[1,1].set_ylabel('Residuals ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis (for Random Forest and Gradient Boosting)\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': all_features,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot top 20 most important features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top 20 Most Important Features ({best_model_name})', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n=== TOP 10 MOST IMPORTANT FEATURES ===\")\n",
    "    for i, row in feature_importance.head(10).iterrows():\n",
    "        print(f\"{row['feature']}: {row['importance']:.4f}\")\n",
    "else:\n",
    "    print(\"Feature importance not available for Linear Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creative Insights and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unusual insights analysis\n",
    "print(\"=== CREATIVE INSIGHTS FROM THE DATA ===\")\n",
    "\n",
    "# 1. Impact of AI tools on salary\n",
    "ai_impact = df.groupby('AI_Tools_Used')['ConvertedCompYearly'].agg(['mean', 'median', 'count'])\n",
    "ai_diff = ai_impact.loc[1, 'median'] - ai_impact.loc[0, 'median']\n",
    "print(f\"\\n1. AI TOOLS PREMIUM:\")\n",
    "print(f\"   Developers using AI tools earn ${ai_diff:,.0f} more (median)\")\n",
    "print(f\"   AI users median: ${ai_impact.loc[1, 'median']:,.0f}\")\n",
    "print(f\"   Non-AI users median: ${ai_impact.loc[0, 'median']:,.0f}\")\n",
    "\n",
    "# 2. Open source contribution impact\n",
    "os_impact = df.groupby('OpenSource_Contributor')['ConvertedCompYearly'].agg(['mean', 'median'])\n",
    "os_diff = os_impact.loc[1, 'median'] - os_impact.loc[0, 'median']\n",
    "print(f\"\\n2. OPEN SOURCE PREMIUM:\")\n",
    "print(f\"   Open source contributors earn ${os_diff:,.0f} more (median)\")\n",
    "\n",
    "# 3. Sweet spot analysis - optimal experience vs age\n",
    "df['Experience_to_Age_Ratio'] = df['YearsCodePro'] / df['Age']\n",
    "high_earners = df[df['ConvertedCompYearly'] > df['ConvertedCompYearly'].quantile(0.8)]\n",
    "print(f\"\\n3. HIGH EARNER PROFILE (Top 20%):\")\n",
    "print(f\"   Average age: {high_earners['Age'].mean():.1f} years\")\n",
    "print(f\"   Average experience: {high_earners['YearsCodePro'].mean():.1f} years\")\n",
    "print(f\"   Experience-to-age ratio: {high_earners['Experience_to_Age_Ratio'].mean():.2f}\")\n",
    "\n",
    "# 4. Company size vs remote work interaction\n",
    "size_remote_salary = df.groupby(['OrgSize', 'Remote'])['ConvertedCompYearly'].median().unstack()\n",
    "print(f\"\\n4. COMPANY SIZE & REMOTE WORK INTERACTION:\")\n",
    "print(\"   Remote work premium varies by company size:\")\n",
    "for size in ['2-9 employees', '100-499 employees', '10,000+ employees']:\n",
    "    if size in size_remote_salary.index:\n",
    "        remote_prem = size_remote_salary.loc[size, 'Fully remote'] - size_remote_salary.loc[size, 'In-office']\n",
    "        print(f\"   {size}: ${remote_prem:,.0f} remote premium\")\n",
    "\n",
    "# 5. Skills diversity impact\n",
    "skills_salary = df.groupby(pd.cut(df['Total_Skills'], bins=5))['ConvertedCompYearly'].median()\n",
    "print(f\"\\n5. SKILLS DIVERSITY IMPACT:\")\n",
    "print(f\"   Salary increases with skill diversity:\")\n",
    "for skill_range, salary in skills_salary.items():\n",
    "    print(f\"   {skill_range}: ${salary:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced insights visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# AI Tools + Open Source combination\n",
    "df['AI_OS_Combo'] = df['AI_Tools_Used'].astype(str) + '_' + df['OpenSource_Contributor'].astype(str)\n",
    "combo_labels = {'0_0': 'Neither', '0_1': 'OS Only', '1_0': 'AI Only', '1_1': 'Both'}\n",
    "df['AI_OS_Label'] = df['AI_OS_Combo'].map(combo_labels)\n",
    "\n",
    "combo_salaries = df.groupby('AI_OS_Label')['ConvertedCompYearly'].median().sort_values()\n",
    "colors = ['red', 'orange', 'lightblue', 'green']\n",
    "axes[0,0].bar(combo_salaries.index, combo_salaries.values, color=colors)\n",
    "axes[0,0].set_title('Salary by AI Tools & Open Source Combination', fontsize=12, fontweight='bold')\n",
    "axes[0,0].set_ylabel('Median Salary ($)')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Experience vs Age scatter with salary color\n",
    "scatter = axes[0,1].scatter(df['Age'], df['YearsCodePro'], c=df['ConvertedCompYearly'], \n",
    "                           cmap='viridis', alpha=0.6, s=30)\n",
    "axes[0,1].set_xlabel('Age')\n",
    "axes[0,1].set_ylabel('Years of Professional Coding')\n",
    "axes[0,1].set_title('Experience vs Age (colored by salary)', fontsize=12, fontweight='bold')\n",
    "plt.colorbar(scatter, ax=axes[0,1], label='Salary ($)')\n",
    "\n",
    "# Skills count distribution by high earners\n",
    "high_earners_mask = df['ConvertedCompYearly'] > df['ConvertedCompYearly'].quantile(0.8)\n",
    "axes[1,0].hist(df[~high_earners_mask]['Total_Skills'], alpha=0.5, label='Bottom 80%', bins=15, density=True)\n",
    "axes[1,0].hist(df[high_earners_mask]['Total_Skills'], alpha=0.7, label='Top 20%', bins=15, density=True)\n",
    "axes[1,0].set_xlabel('Total Skills Count')\n",
    "axes[1,0].set_ylabel('Density')\n",
    "axes[1,0].set_title('Skills Distribution: High vs Low Earners', fontsize=12, fontweight='bold')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Country vs Developer Type heatmap (top countries and roles)\n",
    "top_countries = df['Country'].value_counts().head(8).index\n",
    "top_roles = df['DevType'].value_counts().head(6).index\n",
    "country_role_salary = df[df['Country'].isin(top_countries) & df['DevType'].isin(top_roles)]\n",
    "heatmap_data = country_role_salary.groupby(['Country', 'DevType'])['ConvertedCompYearly'].median().unstack()\n",
    "\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.0f', cmap='YlOrRd', ax=axes[1,1])\n",
    "axes[1,1].set_title('Median Salary Heatmap: Country vs Role', fontsize=12, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Developer Type')\n",
    "axes[1,1].set_ylabel('Country')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creative Predictive Scenarios\n",
    "\n",
    "Let's create interesting scenarios and see what our model predicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define creative scenarios\n",
    "scenarios = {\n",
    "    'The AI-Powered Fresh Graduate': {\n",
    "        'description': 'Recent CS graduate from India, uses AI tools, contributes to open source',\n",
    "        'YearsCodePro': 1,\n",
    "        'Age': 22,\n",
    "        'DatabaseWorkedWith_count': 3,\n",
    "        'LanguageWorkedWith_count': 5,\n",
    "        'PlatformWorkedWith_count': 2,\n",
    "        'AI_Tools_Used': 1,\n",
    "        'OpenSource_Contributor': 1,\n",
    "        'Country': 'India',\n",
    "        'DevType': 'Full-stack developer',\n",
    "        'EdLevel': 'Bachelor\\'s degree',\n",
    "        'OrgSize': '100-499 employees',\n",
    "        'Remote': 'Fully remote'\n",
    "    },\n",
    "    'The Veteran Silicon Valley ML Engineer': {\n",
    "        'description': 'Experienced ML engineer in the US, PhD, works at big tech',\n",
    "        'YearsCodePro': 15,\n",
    "        'Age': 38,\n",
    "        'DatabaseWorkedWith_count': 5,\n",
    "        'LanguageWorkedWith_count': 8,\n",
    "        'PlatformWorkedWith_count': 4,\n",
    "        'AI_Tools_Used': 1,\n",
    "        'OpenSource_Contributor': 1,\n",
    "        'Country': 'United States',\n",
    "        'DevType': 'Machine learning engineer',\n",
    "        'EdLevel': 'PhD',\n",
    "        'OrgSize': '10,000+ employees',\n",
    "        'Remote': 'Hybrid'\n",
    "    },\n",
    "    'The European Startup CTO': {\n",
    "        'description': 'Self-taught CTO of a small startup in Germany, no formal degree',\n",
    "        'YearsCodePro': 12,\n",
    "        'Age': 35,\n",
    "        'DatabaseWorkedWith_count': 6,\n",
    "        'LanguageWorkedWith_count': 10,\n",
    "        'PlatformWorkedWith_count': 5,\n",
    "        'AI_Tools_Used': 1,\n",
    "        'OpenSource_Contributor': 1,\n",
    "        'Country': 'Germany',\n",
    "        'DevType': 'Full-stack developer',\n",
    "        'EdLevel': 'High school',\n",
    "        'OrgSize': '10-19 employees',\n",
    "        'Remote': 'In-office'\n",
    "    },\n",
    "    'The Remote Security Expert': {\n",
    "        'description': 'Security engineer working remotely from Eastern Europe',\n",
    "        'YearsCodePro': 8,\n",
    "        'Age': 31,\n",
    "        'DatabaseWorkedWith_count': 4,\n",
    "        'LanguageWorkedWith_count': 6,\n",
    "        'PlatformWorkedWith_count': 3,\n",
    "        'AI_Tools_Used': 0,  # Security-focused, cautious about AI\n",
    "        'OpenSource_Contributor': 1,\n",
    "        'Country': 'Poland',\n",
    "        'DevType': 'Security engineer',\n",
    "        'EdLevel': 'Master\\'s degree',\n",
    "        'OrgSize': '1,000-4,999 employees',\n",
    "        'Remote': 'Fully remote'\n",
    "    },\n",
    "    'The Brazilian Mobile Dev': {\n",
    "        'description': 'Mobile developer in Brazil, works for a mid-size company',\n",
    "        'YearsCodePro': 5,\n",
    "        'Age': 28,\n",
    "        'DatabaseWorkedWith_count': 2,\n",
    "        'LanguageWorkedWith_count': 4,\n",
    "        'PlatformWorkedWith_count': 3,\n",
    "        'AI_Tools_Used': 1,\n",
    "        'OpenSource_Contributor': 0,\n",
    "        'Country': 'Brazil',\n",
    "        'DevType': 'Mobile developer',\n",
    "        'EdLevel': 'Bachelor\\'s degree',\n",
    "        'OrgSize': '500-999 employees',\n",
    "        'Remote': 'Hybrid'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create prediction function\n",
    "def predict_salary_scenario(scenario_data, model, feature_columns, encoded_columns):\n",
    "    # Create a dataframe with the scenario\n",
    "    scenario_df = pd.DataFrame([scenario_data])\n",
    "    \n",
    "    # Apply same feature engineering\n",
    "    scenario_df['Total_Skills'] = (scenario_df['DatabaseWorkedWith_count'] + \n",
    "                                  scenario_df['LanguageWorkedWith_count'] + \n",
    "                                  scenario_df['PlatformWorkedWith_count'])\n",
    "    \n",
    "    high_paying_countries = ['United States', 'Switzerland', 'Netherlands', 'Germany', 'Australia']\n",
    "    scenario_df['High_Paying_Country'] = scenario_df['Country'].isin(high_paying_countries).astype(int)\n",
    "    \n",
    "    high_demand_roles = ['Machine learning engineer', 'Data scientist', 'Security engineer', 'Data engineer']\n",
    "    scenario_df['High_Demand_Role'] = scenario_df['DevType'].isin(high_demand_roles).astype(int)\n",
    "    \n",
    "    scenario_df['Advanced_Degree'] = scenario_df['EdLevel'].isin(['Master\\'s degree', 'PhD']).astype(int)\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    categorical_features = ['Country', 'DevType', 'EdLevel', 'OrgSize', 'Remote']\n",
    "    scenario_encoded = pd.get_dummies(scenario_df, columns=categorical_features, prefix=categorical_features)\n",
    "    \n",
    "    # Ensure all columns exist (fill missing with 0)\n",
    "    for col in feature_columns:\n",
    "        if col not in scenario_encoded.columns:\n",
    "            scenario_encoded[col] = 0\n",
    "    \n",
    "    # Select and order features to match training data\n",
    "    scenario_features = scenario_encoded[feature_columns].reindex(columns=feature_columns, fill_value=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(scenario_features)[0]\n",
    "    return prediction\n",
    "\n",
    "# Make predictions for all scenarios\n",
    "print(\"=== CREATIVE PREDICTIVE SCENARIOS ===\")\n",
    "print(\"\\nUsing our trained model to predict salaries for different developer profiles:\\n\")\n",
    "\n",
    "scenario_predictions = []\n",
    "for scenario_name, scenario_data in scenarios.items():\n",
    "    try:\n",
    "        predicted_salary = predict_salary_scenario(scenario_data, best_model, all_features, encoded_feature_cols)\n",
    "        scenario_predictions.append({\n",
    "            'scenario': scenario_name,\n",
    "            'description': scenario_data['description'],\n",
    "            'predicted_salary': predicted_salary,\n",
    "            'data': scenario_data\n",
    "        })\n",
    "        \n",
    "        print(f\"📊 {scenario_name}:\")\n",
    "        print(f\"   {scenario_data['description']}\")\n",
    "        print(f\"   Predicted Salary: ${predicted_salary:,.0f}\")\n",
    "        print(f\"   Key factors: {scenario_data['YearsCodePro']} years exp, {scenario_data['Country']}, {scenario_data['DevType']}\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting for {scenario_name}: {e}\")\n",
    "\n",
    "# Sort scenarios by predicted salary\n",
    "scenario_predictions.sort(key=lambda x: x['predicted_salary'], reverse=True)\n",
    "\n",
    "print(\"=== SALARY RANKING ===\")\n",
    "for i, scenario in enumerate(scenario_predictions, 1):\n",
    "    print(f\"{i}. {scenario['scenario']}: ${scenario['predicted_salary']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scenario predictions\n",
    "if scenario_predictions:\n",
    "    scenario_names = [s['scenario'] for s in scenario_predictions]\n",
    "    predicted_salaries = [s['predicted_salary'] for s in scenario_predictions]\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    bars = plt.bar(range(len(scenario_names)), predicted_salaries, \n",
    "                   color=['gold', 'silver', '#CD7F32', 'lightblue', 'lightcoral'])\n",
    "    plt.title('Predicted Salaries for Creative Scenarios', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Predicted Annual Salary ($)', fontsize=12)\n",
    "    plt.xticks(range(len(scenario_names)), [name.replace(' ', '\\n') for name in scenario_names], \n",
    "               rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, salary in zip(bars, predicted_salaries):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2000, \n",
    "                f'${salary:,.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analysis of predictions\n",
    "    print(\"\\n=== SCENARIO ANALYSIS ===\")\n",
    "    \n",
    "    highest = scenario_predictions[0]\n",
    "    lowest = scenario_predictions[-1]\n",
    "    \n",
    "    print(f\"Highest predicted salary: {highest['scenario']} - ${highest['predicted_salary']:,.0f}\")\n",
    "    print(f\"Lowest predicted salary: {lowest['scenario']} - ${lowest['predicted_salary']:,.0f}\")\n",
    "    print(f\"Salary range: ${highest['predicted_salary'] - lowest['predicted_salary']:,.0f}\")\n",
    "    \n",
    "    # Calculate average salary by factors\n",
    "    avg_by_country = {}\n",
    "    avg_by_role = {}\n",
    "    \n",
    "    for scenario in scenario_predictions:\n",
    "        country = scenario['data']['Country']\n",
    "        role = scenario['data']['DevType']\n",
    "        salary = scenario['predicted_salary']\n",
    "        \n",
    "        if country not in avg_by_country:\n",
    "            avg_by_country[country] = []\n",
    "        avg_by_country[country].append(salary)\n",
    "        \n",
    "        if role not in avg_by_role:\n",
    "            avg_by_role[role] = []\n",
    "        avg_by_role[role].append(salary)\n",
    "    \n",
    "    print(\"\\nKey insights from scenarios:\")\n",
    "    print(\"• Location has a massive impact on salary potential\")\n",
    "    print(\"• Specialized roles (ML, Security) command premium salaries\")\n",
    "    print(\"• AI tool usage provides a meaningful salary boost\")\n",
    "    print(\"• Experience and education compound for higher earnings\")\n",
    "    print(\"• Company size significantly affects compensation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings and Conclusions\n",
    "\n",
    "### Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=== FINAL PROJECT SUMMARY ===\")\n",
    "print()\n",
    "print(\"🎯 RESEARCH QUESTIONS ANSWERED:\")\n",
    "print()\n",
    "\n",
    "print(\"1. MOST IMPORTANT FEATURES DRIVING SALARY:\")\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
    "    top_5_features = feature_importance.head(5)\n",
    "    for _, row in top_5_features.iterrows():\n",
    "        print(f\"   • {row['feature']}: {row['importance']:.3f} importance\")\nelse:\n",
    "    print(\"   • Geographic location (US, Switzerland premium)\")\n",
    "    print(\"   • Developer specialization (ML, Security, Data roles)\")\n",
    "    print(\"   • Years of experience\")\n",
    "    print(\"   • Company size\")\n",
    "    print(\"   • Education level\")\n",
    "\n",
    "print(\"\\n2. UNUSUAL/CREATIVE INSIGHTS:\")\n",
    "print(f\"   • AI tool users earn ${ai_diff:,.0f} more than non-users\")\n",
    "print(f\"   • Open source contributors have ${os_diff:,.0f} salary premium\")\n",
    "print(\"   • Remote work premium varies significantly by company size\")\n",
    "print(\"   • Skills diversity correlates strongly with higher salaries\")\n",
    "print(\"   • PhD holders have significant salary advantage over Bachelor's\")\n",
    "\n",
    "print(\"\\n3. MODEL ACCURACY:\")\n",
    "print(f\"   • Best model: {best_model_name}\")\n",
    "print(f\"   • R² Score: {model_results[best_model_name]['test_r2']:.3f}\")\n",
    "print(f\"   • RMSE: ${model_results[best_model_name]['test_rmse']:,.0f}\")\n",
    "print(f\"   • MAE: ${model_results[best_model_name]['test_mae']:,.0f}\")\n",
    "r2_percentage = model_results[best_model_name]['test_r2'] * 100\n",
    "print(f\"   • Model explains {r2_percentage:.1f}% of salary variance\")\n",
    "\n",
    "print(\"\\n4. CREATIVE PREDICTIVE SCENARIOS:\")\n",
    "if scenario_predictions:\n",
    "    for scenario in scenario_predictions:\n",
    "        print(f\"   • {scenario['scenario']}: ${scenario['predicted_salary']:,.0f}\")\n",
    "\n",
    "print(\"\\n🏆 KEY TAKEAWAYS:\")\n",
    "print(\"   • Geographic arbitrage is the strongest salary factor\")\n",
    "print(\"   • Specialization in AI/ML/Security pays premium\")\n",
    "print(\"   • Modern skills (AI tools) provide competitive advantage\")\n",
    "print(\"   • Open source contribution signals quality to employers\")\n",
    "print(\"   • Company size matters more than remote vs office\")\n",
    "print(\"   • Education provides foundation, but experience amplifies earnings\")\n",
    "\n",
    "print(\"\\n📊 MODEL RELIABILITY:\")\n",
    "if model_results[best_model_name]['test_r2'] > 0.8:\n",
    "    print(\"   ✅ Excellent - Model predictions are highly reliable\")\nelif model_results[best_model_name]['test_r2'] > 0.6:\n",
    "    print(\"   ✅ Good - Model captures most salary patterns\")\nelif model_results[best_model_name]['test_r2'] > 0.4:\n",
    "    print(\"   ⚠️ Moderate - Model captures general trends\")\nelse:\n",
    "    print(\"   ❌ Poor - Model has limited predictive power\")\n",
    "\n",
    "mae_percentage = (model_results[best_model_name]['test_mae'] / df['ConvertedCompYearly'].mean()) * 100\n",
    "print(f\"   • Average prediction error: {mae_percentage:.1f}% of mean salary\")\n",
    "\n",
    "print(\"\\n✨ This analysis provides a comprehensive view of developer compensation\")\n",
    "print(\"   patterns and can guide career decisions and salary negotiations.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}